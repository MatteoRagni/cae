#!/usr/bin/env python3

# Importing libraries
# For using my GPU I have to do that...
# export TF_MIN_GPU_MULTIPROCESSOR_COUNT=2

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import sys
sys.path.insert(0, './lib')

import os
from timer import Timer
import timer
from argparse import ArgumentParser
from data_handler import DataHandler
from autoenc_shell import ConvAutoEncShell
import tensorflow as tf


# Parsing command line arguments
class ConvAutoEncArgParse(ArgumentParser):

    def initialize(self):
        self.identifier = timer.timestring()

        # Id options
        self.add_argument('-id', '--identifier', dest='identifier', type=str, nargs=1, default=[self.identifier],
            help='Training identifier - time base [{}]'.format(self.identifier))

        # File options
        self.add_argument('-w', '--workspace', dest='workspace', type=str, nargs=1, required=True,
            help='Workspace directory. Will contain run files generated during training and inference')
        self.add_argument('-d', dest='dataset', type=str, nargs=1, required=True,
            help='Dataset directory. Must contain training and inference datasets')
        self.add_argument('-m', '--model', dest='model', type=str, nargs=1, required=True,
            help='Model binary file')

        self.add_argument('--training-id', dest='training_id', type=str, nargs=1,
            default=['train-' + self.identifier],
            help='Run directory will be created inside workspace')
        self.add_argument('-s', '--save', dest='save_file', type=str, nargs=1,
            help='Checkpoint saving file')
        self.add_argument('-l', '--load', dest='load_file', type=str, nargs=1,
            help='Checkpoint loading file (will skip training)')

        # Training options
        self.add_argument('-bs', '--batch-size', dest='batch_size', type=int, nargs=1, default=10,
            help='Batch size (number of examples for learning step)')
        self.add_argument('-sz', '--step-size', dest='step_size', type=int, nargs=1, default=10,
            help='Number of reiteratios on a single batch')
        self.add_argument('-bb', '--batch-block', dest='batch_block', type=int, nargs=1, default=8,
            help='Number of blocks of batches to be loaded (1 batch = 1000 figures)')

        self.add_argument('--learning-rate', dest='learn_rate', type=float, nargs=1, default=0.001,
            help='Learning rate hyper-parameters')
        self.add_argument('--residual-learning', dest='residuals', action='store_true',
            help='Enable residual learning (NO -> y = f(g(x)), YES -> y = f(g(x)) + x) [NO]')

        # Other Options
        self.add_argument('--notify', dest='notification', action='store_true', default=False,
            help='Enable notifications using system telegram bot, at the end of the learning')

    def run(self):
        self.parse_args()
        return self._handleFiles()._handleTraining()

    def _handleFiles(self):
        self.training_file  = os.path.join(' '.join(self.dataset), 'training.pickle')
        self.inference_file = os.path.join(' '.join(self.dataset), 'inference.pickle')
        self.model = os.path.join(' '.join(self.model))
        self.load_file = os.path.join(' '.join(self.load_file))
        self.save_file = os.path.join(' '.join(self.save_file))

        assert os.path.isfile(self.training_file),
            "Dataset file {} does not exist".format(self.training_file)
        assert os.path.isfile(self.inference_file),
            "Inference file {} does not exist".format(self.inference_file)
        assert os.path.isfile(self.model),
            "Model file {} does not exist".format(self.model)
        assert os.path.isfile(self.load_file),
            "Restored model {} does not exist".format(self.load_file)

        self.workspace = os.path.join(' '.join(self.workspace))
        self.training_dir = os.path.join(self.workspace, self.training_dir)
        return self

    def _handleTraining(self):
        if type(self.batch_size) is list:
            self.batch_size = self.batch_size[0]
        assert self.batch_size > 0, "Batch size must be positive"
        if type(self.step_size) is list:
            self.step_size = self.step_size[0]
        assert self.step_size > 0, "Batch size must be positive"
        if type(self.batch_block) is list:
            self.batch_block = self.batch_block[0]
        assert self.batch_block > 0, "Batch size must be positive"
        if type(self.learn_rate) is list:
            self.learn_rate = self.learn_rate[0]
        assert self.learn_rate > 0, "Batch size must be positive"
        return self


cmd = ConvAutoEncArgParse(prog="caes-bin",
    description="Stacked Convolutional Autoencoder",
    epilog="Matteo Ragni, David Windridge, Paolo Bosetti - 2016")

cmd_args = cmd.run()

###################################################################################################
###################################################################################################
###################################################################################################
###################################################################################################


# Handles the command line arguments and check everything is ok

if cmd_args.verb > 3:
    VERBOSITY = 3
elif cmd_args.verb < 0:
    VERBOSITY = 0

def batch_loop(length):
    VERBOSITY = cmd_args.verb[0]

# DEVICE_PLACEMENT_LOG = True if VERBOSITY > 1 else False
DEVICE_PLACEMENT_LOG = False

# Telegram notifications
if cmd_args.telegram:
    from tg_notifier import TelegramNotifier
    notifier = TelegramNotifier()
    def notify(m):
        notifier.post(m)
else:
    def notify(m):
        pass

# Logging function
def log(s, l=1):
    if l >= VERBOSITY:
        print(s)
    if l == 1:
        notify(str(s))

# MAIN PART
from six.moves import cPickle as pickle
import numpy as np
import tensorflow as tf
import autoencoder


# Some definitions on the engine
FLAGS = tf.app.flags.FLAGS
tf.app.flags.DEFINE_string('dataset_file',
                           cmd_args.dataset[0],
                           "Dataset file for training")
tf.app.flags.DEFINE_string('support_file',
                           cmd_args.support[0],
                           "Dataset file for support the training")
tf.app.flags.DEFINE_string('train_dir',
                           cmd_args.runs,
                           "Training directory")
tf.app.flags.DEFINE_string('saver_dir',
                           cmd_args.save,
                           "Chackpoint file for saving")
tf.app.flags.DEFINE_integer('max_steps',
                            cmd_args.stepsize,
                            "Number of steps for the optimizer on each batch")
tf.app.flags.DEFINE_integer('batch_size',
                            cmd_args.batchsize,
                            "Number of elements in each batch")
tf.app.flags.DEFINE_boolean('log_device_placement',
                            DEVICE_PLACEMENT_LOG,
                            "Logging of the use of my device")
tf.app.flags.DEFINE_boolean('gpu_enabled',
                            cmd_args.gpu,
                            "Enables the use of GPU for Convolutions")
tf.app.flags.DEFINE_boolean('cumulate_error',
                            cmd_args.cumulate_error,
                            "Enables the use of cumulative errors")
tf.app.flags.DEFINE_float('learning_rate',
                          cmd_args.learnrate,
                          "Optimizer learning rate")

#  _                 _ _              ___               _
# | |   ___  __ _ __| (_)_ _  __ _   / __|_ _ __ _ _ __| |_
# | |__/ _ \/ _` / _` | | ' \/ _` | | (_ | '_/ _` | '_ \ ' \
# |____\___/\__,_\__,_|_|_||_\__, |  \___|_| \__,_| .__/_||_|
#                            |___/                |_|
print("Loading the graph...")
with open(' '.join(cmd_args.cae_config), "rb") as fp:
    try:
        sets = pickle.load(fp)
    except Exception as e:
        print(("ERROR: {}").format(e))
        exit(1)

for s in sets:
    s.input_shape[0] = FLAGS.batch_size
print("Done!")

stack = autoencoder.ConvAutoEncStack(sets)

#              _
#  ___ _ _  __| |
# / -_) ' \/ _` |
# \___|_||_\__,_|


# Check if there is a checkpoint to restore
# RESTORE = os.path.isfile(FLAGS.saver_dir)

# Loading the Convolutional Autoencoder
merged = tf.merge_all_summaries()
writer = tf.train.SummaryWriter(FLAGS.train_dir, stack.graph)
counter = 0

# try:
dh = DataHandler(FLAGS.dataset_file, FLAGS.support_file, tuple(sets[0].input_shape))
losses_string = ""
# stack.writeConfiguration(os.path.join(FLAGS.train_dir, "config.txt"))

if cmd_args.single_opt:
    result = [None, 99999999.9999999]
    session = stack.session

    with tf.name_scope("TRAINING"):

        current_batch = -1
        for batch_no, dataset in dh.loop(FLAGS.batch_size, BATCH_LIMIT):

            if current_batch != batch_no:
                current_batch = batch_no
                log("RUNNING BATCH: %d (c: %i, e: %5.10f) on single layer" % (current_batch, counter, result[1]))

            with Timer():  # batch timing

                for step in range(0, FLAGS.max_steps):
                    result = session.run([stack.optimizer], feed_dict={stack.caes[0].x: dataset[0]})
                    counter += 1

                # Handling the losses at the end of an optimization run
                losses = 0
                loss_string = "%d" % counter
                for im in dataset:
                    loss = session.run(stack.error, feed_dict={stack.caes[0].x: im})
                    loss_string += "\t%f" % loss
                    losses += loss
                loss_string += "\t%f\n" % losses
                log("Loss report => " + loss_string)
                losses_string += loss_string

                result = session.run([merged, stack.error], feed_dict={stack.caes[0].x: dataset[0]})
                log("Error at step %i is: %5.10f" % (counter, result[1]), 2)
                writer.add_summary(result[0], counter)

else:
    for session, n, cae, x in stack.trainBlocks():
        result = [None, 99999999.9999999]

        with tf.name_scope("TRAINING-%d" % n):

            current_batch = -1
            for batch_no, dataset in dh.loop(FLAGS.batch_size, BATCH_LIMIT):

                if current_batch != batch_no:
                    current_batch = batch_no
                    log("RUNNING BATCH: %d (c: %i, e: %5.10f) on layer %d" % (current_batch, counter, result[1], n))

                with Timer():  # batch timing

                    for step in range(0, FLAGS.max_steps):
                        result = session.run([cae.optimizer], feed_dict={x: dataset[0]})
                        counter += 1

                    # Handling the losses at the end of an optimization run
                    losses = 0
                    loss_string = "%d" % counter
                    for im in dataset:
                        loss = session.run(stack.error, feed_dict={x: im})
                        loss_string += "\t%f" % loss
                        losses += loss
                    loss_string += "\t%f\n" % losses
                    log("Loss report => " + loss_string)
                    losses_string += loss_string

                    result = session.run([merged, cae.error], feed_dict={x: dataset[0]})
                    log("Error at step %i is: %5.10f" % (counter, result[1]), 2)
                    writer.add_summary(result[0], counter)


with open(os.path.join(FLAGS.train_dir, "loss_report.csv"), "w") as f:
    f.write(losses_string)

stack.save("/tmp/results.ckpt")

# from autoenc_shell import ConvAutoEncShell
ConvAutoEncShell({
    "objects": 3,
    "positions": 25,
    "session": session,
    "stack": stack,
    "counter": counter,
    "writer": writer,
    "dh": dh,
    "summary": merged
}).cmdloop()

# finally:
#   stack.close()
log("Learning Completed")
notify("Learning completed")
exit(0)
